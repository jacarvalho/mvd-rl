import numpy as np

from mushroom_rl.algorithms.agent import Agent
from mushroom_rl.utils.dataset import compute_J


class EMVD(Agent):
    """
    Episodic Black Box optimization algorithms using Measure-Valued Derivatives.
    Works on a distribution of policy parameters and does not rely
    on stochastic and differentiable policies.

    """
    def __init__(self, mdp_info, distribution, policy, grad_optimizer,
                 mc_samples_gradient=1, coupling=False, features=None):
        """
        Constructor.

        Args:
            distribution (Distribution): the distribution of policy parameters;
            policy (ParametricPolicy): the policy to use.

        """
        self.distribution = distribution
        self._theta_list = list()

        self.grad_optimizer = grad_optimizer

        self._add_save_attr(distribution='mushroom', _theta_list='pickle')
        self._add_save_attr(learning_rate='pickle')

        super().__init__(mdp_info, policy, features)

        self.mc_samples_gradient = mc_samples_gradient
        self._coupling = coupling
        self._theta_idx = 0
        self._theta_mvd = None

        self._eval = False

    def set_eval(self, eval_policy=False):
        self._eval = eval_policy

    def episode_start(self):
        if self._eval:
            theta = self.distribution.sample()
        else:
            if self._theta_idx == 0:
                # Generate the first set of parameters for the mvd
                self._theta_mvd = self.distribution.generate_mvd_theta(self._coupling)

            theta = self._theta_mvd[self._theta_idx]
            self._theta_idx += 1

        self._theta_list.append(theta)
        self.policy.set_weights(theta)

        super().episode_start()
        self._episode_end()

    def _episode_end(self):
        if self._theta_idx == self.distribution.theta_mvd_size:
            # If more than one MC gradient estimate is required.
            # Reset the theta index, if it reaches the number of thetas generated by the mvd.
            self._theta_idx = 0

    def fit(self, dataset):
        Jep = compute_J(dataset, self.mdp_info.gamma)

        Jep = np.array(Jep).reshape((self.mc_samples_gradient,
                                     self.distribution.theta_mvd_size,
                                     1))
        theta = np.array(self._theta_list).reshape((self.mc_samples_gradient,
                                                    self.distribution.theta_mvd_size,
                                                    self.distribution.dim))

        self._update(Jep, theta)

        self._theta_list = list()

    def stop(self):
        self._theta_list = list()
        self._theta_idx = 0

    def _update(self, Jep, theta):
        grad_J_all = np.empty((self.distribution.parameters_size, self.mc_samples_gradient))
        for i in range(self.mc_samples_gradient):
            # Compute the gradient estimate for every MC sample
            grad_theta_mc = self.distribution.grad_mvd_params(theta[i, :, :], Jep[i, :, :])
            grad_J_all[:, i] = grad_theta_mc[:, 0]

        grad_J = np.mean(grad_J_all, axis=1)

        # Apply the gradient
        omega = self.distribution.get_parameters()
        omega = self.grad_optimizer(omega, grad_J)
        self.distribution.set_parameters(omega)
