import torch
import torch.distributions as torchdist
from torch.distributions import constraints
from torch.distributions.distribution import Distribution


class DoubleSidedStandardMaxwell(Distribution):
    """
    Adapted from https://github.com/deepmind/mc_gradients
    Creates a Double-Sided Standard Maxwell distribution with parameters loc=0., scale=1.
    This distribution is useful to compute measure valued derivatives for Gaussian distributions.

    #### Mathematical details

    The double-sided Maxwell distribution generalizes the Maxwell distribution to the entire real line.

    ```none
    pdf(x; mu, sigma) = 1/(sigma*sqrt(2*pi)) * ((x-mu)/sigma)^2 * exp(-0.5 ((x-mu)/sigma)^2)
    ```
    where `loc = mu` and `scale = sigma`.

    The DoublesidedMaxwell distribution is a member of the
    [location-scale family](https://en.wikipedia.org/wiki/Location-scale_family), i.e., it can be constructed as,

    ```none
    X ~ DoublesidedMaxwell(loc=0, scale=1)
    Y = loc + scale * X
    ```

    The double-sided Maxwell is a symmetric distribution that extends the one-sided maxwell from R+ to the
    entire real line. Their densities are therefore the same up to a factor of 0.5.

    It has several methods for generating random variates from it. The version here uses 3 Gaussian variates and a
    uniform variate to generate the samples. The sampling path for a double-sided Maxwell(mu, sigma) is:
    mu + sigma* sgn(U-0.5)* sqrt(X^2 + Y^2 + Z^2) U~Unif; X,Y,Z ~N(0,1)

    For the STANDARD double-sided Maxwell(0., 1.), the sampling path is
    sgn(U-0.5)* sqrt(X^2 + Y^2 + Z^2) U~Unif; X,Y,Z ~N(0,1)

    In the sampling process above, the random variates generated by sqrt(X^2 + Y^2 + Z^2) are samples from the
    one-sided Maxwell (or Maxwell-Boltzmann) distribution.

    """

    support = constraints.real
    has_rsample = True

    def __init__(self, validate_args=None):
        self._uniform = torchdist.uniform.Uniform(low=0., high=1.)

        self._gaussian1 = torchdist.normal.Normal(loc=0., scale=1.)
        self._gaussian2 = torchdist.normal.Normal(loc=0., scale=1.)
        self._gaussian3 = torchdist.normal.Normal(loc=0., scale=1.)

        batch_shape = torch.Size()
        super(DoubleSidedStandardMaxwell, self).__init__(batch_shape, validate_args=validate_args)

    def rsample(self, sample_shape=torch.Size(())):
        shape = self._extended_shape(sample_shape)
        X = self._gaussian1.rsample(sample_shape).view(shape)
        Y = self._gaussian2.rsample(sample_shape).view(shape)
        Z = self._gaussian3.rsample(sample_shape).view(shape)

        U = self._uniform.rsample(sample_shape).view(shape)

        sgn = torch.sign(U - 0.5)

        # Samples from the one-sided Maxwell-Boltzamnn distribution
        MB = torch.sqrt(torch.pow(X, 2) + torch.pow(Y, 2) + torch.pow(Z, 2))

        dsm = sgn * MB

        self._validate_sample(dsm)

        return dsm


def standard_gaussian_from_standard_dsmaxwell(std_dsmaxwell_samples):
    """
    Adapted from https://github.com/deepmind/mc_gradients
    Generate Gaussian variates from Double-sided Maxwell variates.

    Useful for coupling samples from Gaussian and double_sided Maxwell dist.
    1. Generate ds-maxwell variates: dsM ~ dsMaxwell(0,1)
    2. Generate uniform variates: u ~ Unif(0,1)
    3. multiply y = u * dsM
    The result is Gaussian distribution N(0,1) which can be loc-scale adjusted.

    Args:
        std_dsmaxwell_samples: Samples generated from a zero-mean, unit variance
                               double-sided Maxwell distribution M(0,1).
    Returns:
        Tensor of Gaussian variates with the same shape as the input.
    """
    unif_rvs = torchdist.uniform.Uniform(low=0., high=1.).sample(std_dsmaxwell_samples.shape)
    gaussian_rvs = unif_rvs * std_dsmaxwell_samples

    return gaussian_rvs
